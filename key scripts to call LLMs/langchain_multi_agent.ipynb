{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import LangChainTracer\n",
    "from langsmith import Client\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from typing import List, Union\n",
    "import clingo\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "\n",
    " \n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    " \n",
    "# Initialize LangSmith client\n",
    "client = Client()\n",
    "\n",
    "# Step 1: Convert natural language to atomic facts\n",
    "nl_to_facts_prompt = PromptTemplate(\n",
    "    input_variables=[\"nl_input\"],\n",
    "    template=\"Convert the following natural language into atomic facts:\\n{nl_input}\\n\\nAtomic facts:\"\n",
    ")\n",
    "\n",
    "nl_to_facts_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=nl_to_facts_prompt,\n",
    "    verbose=True,\n",
    "    tags=[\"nl_to_facts\"],\n",
    ")\n",
    "\n",
    "# Step 2: Add rules to form complete ASP program\n",
    "asp_rules_prompt = PromptTemplate(\n",
    "    input_variables=[\"atomic_facts\"],\n",
    "    template=\"Given these atomic facts:\\n{atomic_facts}\\n\\nAdd rules to form a complete ASP program:\"\n",
    ")\n",
    "\n",
    "asp_rules_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=asp_rules_prompt,\n",
    "    verbose=True,\n",
    "    tags=[\"asp_rules\"],\n",
    ")\n",
    "\n",
    "# Step 3: Debug ASP program\n",
    "debug_asp_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_program\"],\n",
    "    template=\"Debug the following ASP program and correct any syntax errors:\\n{asp_program}\\n\\nCorrected ASP program:\"\n",
    ")\n",
    "\n",
    "debug_asp_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=debug_asp_prompt,\n",
    "    verbose=True,\n",
    "    tags=[\"debug_asp\"],\n",
    ")\n",
    "\n",
    "# Step 4: Run ASP program\n",
    "def run_asp_program(asp_program: str) -> List[str]:\n",
    "    ctl = clingo.Control()\n",
    "    ctl.add(\"base\", [], asp_program)\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    models = []\n",
    "    with ctl.solve(yield_=True) as handle:\n",
    "        for model in handle:\n",
    "            models.append(str(model))\n",
    "    return models\n",
    "\n",
    "# Step 5: Choose best answer\n",
    "choose_answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_results\", \"original_question\"],\n",
    "    template=\"Given these ASP results:\\n{asp_results}\\n\\nAnd the original question:\\n{original_question}\\n\\nChoose the best answer:\"\n",
    ")\n",
    "\n",
    "choose_answer_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=choose_answer_prompt,\n",
    "    verbose=True,\n",
    "    tags=[\"choose_answer\"],\n",
    ")\n",
    "\n",
    "# Define tools for the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"NL to Facts\",\n",
    "        func=nl_to_facts_chain.run,\n",
    "        description=\"Convert natural language to atomic facts\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ASP Rules\",\n",
    "        func=asp_rules_chain.run,\n",
    "        description=\"Add rules to form complete ASP program\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Debug ASP\",\n",
    "        func=debug_asp_chain.run,\n",
    "        description=\"Debug the ASP program and correct any syntax errors\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Run ASP\",\n",
    "        func=run_asp_program,\n",
    "        description=\"Run the ASP program and return results\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Choose Answer\",\n",
    "        func=choose_answer_chain.run,\n",
    "        description=\"Choose the best answer from ASP results\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define agent prompt\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "agent_prompt = CustomPromptTemplate(\n",
    "    template=\"\"\"Answer the following question as best you can:\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\",\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Define LLM chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=agent_prompt)\n",
    "\n",
    "# Define agent\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=None,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=[tool.name for tool in tools]\n",
    ")\n",
    "\n",
    "# Create agent executor\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Function to process the JSON file and run the pipeline\n",
    "def process_json_file(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    results = []\n",
    "    for item in data:\n",
    "        context = item.get('context', '')\n",
    "        question = item.get('question', '')\n",
    "        predicted_asp = item.get('predicted', '')\n",
    "\n",
    "        # Run the pipeline\n",
    "        with LangChainTracer(client=client) as tracer:\n",
    "            atomic_facts = nl_to_facts_chain.run(nl_input=question)\n",
    "            asp_program = asp_rules_chain.run(atomic_facts=atomic_facts)\n",
    "            corrected_asp = debug_asp_chain.run(asp_program=asp_program)\n",
    "            asp_results = run_asp_program(corrected_asp)\n",
    "            best_answer = choose_answer_chain.run(asp_results=asp_results, original_question=question)\n",
    "\n",
    "        results.append({\n",
    "            \"context\": context,\n",
    "            \"question\": question,\n",
    "            \"predicted\": predicted_asp,\n",
    "            \"actual_answer\": item.get('answer', ''),\n",
    "            \"atomic_facts\": atomic_facts,\n",
    "            \"asp_program\": asp_program,\n",
    "            \"corrected_asp\": corrected_asp,\n",
    "            \"asp_results\": asp_results,\n",
    "            \"best_answer\": best_answer\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Process the JSON file and save the results\n",
    "input_json_file = \"results_optimized.json\"\n",
    "output_json_file = \"results_with_pipeline_output.json\"\n",
    "results = process_json_file(input_json_file)\n",
    "\n",
    "with open(output_json_file, 'w') as file:\n",
    "    json.dump(results, file, indent=4)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "import clingo\n",
    "from typing import List\n",
    "\n",
    "# Initialize OpenAI LLM\n",
    "llm = OpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_base=\"https://api.deepseek.com\",\n",
    "\n",
    "    model_type='chat',\n",
    "    max_tokens=4096,\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.1,\n",
    "    presence_penalty=0.1,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "# Step 1: Convert natural language to atomic facts\n",
    "nl_to_facts_prompt = PromptTemplate(\n",
    "    input_variables=[\"nl_input\"],\n",
    "    template=\"Convert the following natural language into atomic facts:\\n{nl_input}\\n\\nAtomic facts:\"\n",
    ")\n",
    "\n",
    "nl_to_facts_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=nl_to_facts_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Step 2: Add rules to form complete ASP program\n",
    "asp_rules_prompt = PromptTemplate(\n",
    "    input_variables=[\"atomic_facts\"],\n",
    "    template=\"Given these atomic facts:\\n{atomic_facts}\\n\\nAdd rules to form a complete ASP program:\"\n",
    ")\n",
    "\n",
    "asp_rules_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=asp_rules_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Step 3: Debug ASP program\n",
    "debug_asp_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_program\"],\n",
    "    template=\"Debug the following ASP program and correct any syntax errors:\\n{asp_program}\\n\\nCorrected ASP program:\"\n",
    ")\n",
    "\n",
    "debug_asp_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=debug_asp_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Step 4: Run ASP program\n",
    "def run_asp_program(asp_program: str) -> List[str]:\n",
    "    ctl = clingo.Control()\n",
    "    ctl.add(\"base\", [], asp_program)\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    results = []\n",
    "    with ctl.solve(yield_=True) as handle:\n",
    "        for model in handle:\n",
    "            results.append(str(model))\n",
    "    return results\n",
    "\n",
    "# Step 5: Choose best answer\n",
    "choose_answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_results\", \"original_question\"],\n",
    "    template=\"Given these ASP results:\\n{asp_results}\\n\\nAnd the original question:\\n{original_question}\\n\\nChoose the best answer:\"\n",
    ")\n",
    "\n",
    "choose_answer_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=choose_answer_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Main pipeline function\n",
    "def pipeline(nl_input: str, original_question: str) -> str:\n",
    "    # Step 1: Convert natural language to atomic facts\n",
    "    atomic_facts = nl_to_facts_chain.run(nl_input=nl_input)\n",
    "\n",
    "    # Step 2: Add rules to form complete ASP program\n",
    "    asp_program = asp_rules_chain.run(atomic_facts=atomic_facts)\n",
    "\n",
    "    # Step 3: Debug ASP program\n",
    "    debugged_asp_program = debug_asp_chain.run(asp_program=asp_program)\n",
    "\n",
    "    # Step 4: Run ASP program\n",
    "    asp_results = run_asp_program(debugged_asp_program)\n",
    "\n",
    "    # Step 5: Choose the best answer\n",
    "    best_answer = choose_answer_chain.run(asp_results=asp_results, original_question=original_question)\n",
    "\n",
    "    return best_answer\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    nl_input = \"A person wants to know if they can go to the park.\"\n",
    "    original_question = \"Can I go to the park if it is raining?\"\n",
    "    \n",
    "    answer = pipeline(nl_input, original_question)\n",
    "    print(\"Best Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Runnable, RunnablePassthrough, LangChainPredict, StrOutputParser, Memory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import clingo\n",
    "\n",
    "# Initialize OpenAI LLM\n",
    "llm = OpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_base=\"https://api.deepseek.com\",\n",
    "    api_key=\"\",\n",
    "    model_type='chat',\n",
    "    max_tokens=4096,\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.1,\n",
    "    presence_penalty=0.1,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "# Step 1: Convert natural language to atomic facts\n",
    "nl_to_facts_prompt = PromptTemplate(\n",
    "    input_variables=[\"nl_input\"],\n",
    "    template=\"Convert the following natural language into atomic facts:\\n{nl_input}\\n\\nAtomic facts:\"\n",
    ")\n",
    "\n",
    "# Step 2: Add rules to form complete ASP program\n",
    "asp_rules_prompt = PromptTemplate(\n",
    "    input_variables=[\"atomic_facts\"],\n",
    "    template=\"Given these atomic facts:\\n{atomic_facts}\\n\\nAdd rules to form a complete ASP program:\"\n",
    ")\n",
    "\n",
    "# Step 3: Debug ASP program\n",
    "debug_asp_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_program\"],\n",
    "    template=\"Debug the following ASP program and correct any syntax errors:\\n{asp_program}\\n\\nCorrected ASP program:\"\n",
    ")\n",
    "\n",
    "# Step 4: Run ASP program\n",
    "def run_asp_program(asp_program: str) -> str:\n",
    "    ctl = clingo.Control()\n",
    "    ctl.add(\"base\", [], asp_program)\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    results = []\n",
    "    with ctl.solve(yield_=True) as handle:\n",
    "        for model in handle:\n",
    "            results.append(str(model))\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# Step 5: Choose best answer\n",
    "choose_answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"asp_results\", \"original_question\"],\n",
    "    template=\"Given these ASP results:\\n{asp_results}\\n\\nAnd the original question:\\n{original_question}\\n\\nChoose the best answer:\"\n",
    ")\n",
    "\n",
    "# Define the pipeline using LCEL with memory\n",
    "memory = Memory()\n",
    "\n",
    "pipeline = (\n",
    "    RunnablePassthrough.assign(nl_input=\"A person wants to know if they can go to the park.\")  # Replace with dynamic input\n",
    "    | LangChainPredict(prompt=nl_to_facts_prompt, llm=llm)  # Convert to atomic facts\n",
    "    | memory.store(\"atomic_facts\")  # Store atomic facts in memory\n",
    "    | RunnablePassthrough.assign(atomic_facts=lambda x: x)  # Pass atomic facts to the next step\n",
    "    | LangChainPredict(prompt=asp_rules_prompt, llm=llm)  # Generate ASP program\n",
    "    | LangChainPredict(prompt=debug_asp_prompt, llm=llm)  # Debug ASP program\n",
    "    | RunnablePassthrough.assign(asp_program=lambda x: x)  # Pass debugged ASP program to the next step\n",
    "    | Runnable(lambda x: run_asp_program(x))  # Run ASP program\n",
    "    | memory.store(\"asp_results\")  # Store ASP results in memory\n",
    "    | LangChainPredict(prompt=choose_answer_prompt, llm=llm)  # Choose the best answer\n",
    ")\n",
    "\n",
    "# Execute the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    original_question = \"Can I go to the park if it is raining?\"\n",
    "    result = pipeline.invoke({\"nl_input\": \"A person wants to know if they can go to the park.\", \"original_question\": original_question})\n",
    "    print(\"Best Answer:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
